import os
import sys
from typing import Optional
import logging
import re

# Disable LangChain debug logs
logging.getLogger("langchain").setLevel(logging.ERROR)
import langchain
langchain.debug = False

# Import LangChain Community utilities and (we no longer use HuggingFacePipeline)
from langchain_community.utilities import SQLDatabase

from sqlalchemy import create_engine, inspect, text

import torch
# We no longer use transformers for model loading

# ----- New: Use Mistral-7B-Instruct-v0-2.Q4_km.gguf via llama-cpp-python -----
from llama_cpp import Llama

# Define a wrapper so our LLM interface remains the same:
class MistralLLM:
    def __init__(self, model_path: str, n_ctx: int, n_threads: int, verbose: bool):
        print("⏳ Loading Mistral-7B-Instruct model (llama-cpp)...")
        self.llama = Llama(
            model_path=model_path,
            n_ctx=n_ctx,
            n_threads=n_threads,
            verbose=verbose
        )
        print("✅ Model loaded!")
    
    def __call__(self, prompt: str) -> str:
        # Call the model and return the generated text.
        output = self.llama(
            prompt,
            max_tokens=512,
            stop=["</s>","SQL:"])
        # Expecting output in the form: {"choices": [{"text": "..."}], ...}
        return output["choices"][0]["text"].strip()

# Set your model path and parameters here:
SQLCODER_MODEL_PATH = "sqlcoder-7b-2.Q4_K_M.gguf"  # replace with your actual file name

def load_sqlcoder_llm():
    return MistralLLM(
        model_path=SQLCODER_MODEL_PATH,  # same wrapper class
        n_ctx=2048,                      # or 1024 if you want smaller context
        n_threads=6,                     # match your CPU cores
        verbose=False
    )

def pick_tables(question: str, all_tables: list, llm) -> list:
    """
    Uses the LLM to intelligently select relevant tables from the available list,
    based on the user's natural language question.
    """
    prompt = (
        "Given the following list of database tables:\n"
        f"{', '.join(all_tables)}\n\n"
        f"And the user's question:\n\"{question}\"\n\n"
        "Return the names of the most relevant tables from the list. "
        "Only return a comma-separated list of table names. Do not include any explanation or extra text.\n"
    )

    try:
        response = llm(prompt)
        selected = [t.strip() for t in response.split(",") if t.strip() in all_tables]
        return selected or all_tables[:3]  # fallback if model gives invalid output
    except Exception as e:
        print(f"⚠️ LLM table selection failed: {e}")
        return all_tables[:3]

def get_schema_text(db: SQLDatabase, db_uri: str) -> str:
    """
    Build a compact, LLM-optimized schema representation for SQL generation.
    Includes the initially selected tables and any 1-hop foreign key-related tables.
    """
    engine = create_engine(db_uri)
    inspector = inspect(engine)

    # Start with tables included in the filtered DB
    initial_tables = set(db.get_usable_table_names())
    all_tables_to_include = set(initial_tables)

    # Step 1: Add 1-hop foreign key related tables
    for tbl in initial_tables:
        try:
            fks = inspector.get_foreign_keys(tbl)
            for fk in fks:
                referred_table = fk.get("referred_table")
                if referred_table:
                    all_tables_to_include.add(referred_table)
        except Exception:
            continue  # skip faulty FKs

    lines = []

    # Step 2: Format schema for all included tables
    for tbl in sorted(all_tables_to_include):
        try:
            cols = inspector.get_columns(tbl)
            col_defs = [f"{col['name']} {col['type']}" for col in cols]
            col_str = ", ".join(col_defs)
            lines.append(f"TABLE {tbl} ({col_str})")
        except Exception:
            lines.append(f"TABLE {tbl} ([Error reading columns])")

        try:
            fks = inspector.get_foreign_keys(tbl)
            for fk in fks:
                for col, ref_col in zip(fk.get("constrained_columns", []), fk.get("referred_columns", [])):
                    referred_table = fk.get("referred_table", "Unknown")
                    lines.append(f"FK {tbl}.{col} -> {referred_table}.{ref_col}")
        except Exception:
            lines.append(f"# [Error reading foreign keys for {tbl}]")

        lines.append("")  # Add a blank line between tables

    return "\n".join(lines).strip()


def extract_sql_query(text: str) -> str:
    """
    Extracts the SQL query from the model's response.
    Removes ```sql blocks and grabs the first valid SQL statement.
    """
    # Remove markdown-style SQL code block (```sql ... ```)
    text = text.strip()
    if text.startswith("```sql"):
        text = text.removeprefix("```sql").strip()
    if text.endswith("```"):
        text = text.removesuffix("```").strip()

    # Now extract the actual SQL query
    pattern = re.compile(r"(?i)(SELECT|INSERT|UPDATE|DELETE).*?;", re.DOTALL)
    match = pattern.search(text)
    if match:
        return match.group(0).strip()
    else:
        return text.strip()
def generate_sql_custom(question: str, schema_text: str, llm) -> str:
    """
    Manually constructs a prompt (similar to your base version) and uses the LLM
    to generate a SQL query.
    """
    prompt = (
        "Generate an SQL query strictly based on the schema provided.\n\n"
        f"Schema:\n{schema_text}\n\n"
        f"Question:\n{question}\n\n"
        "Only output SQL code. Do not output any explanation or additional text.\n"
        "SQL:"
    )
    result = llm(prompt)
    return result.strip()

from langchain_community.utilities import SQLDatabase
from sqlalchemy import create_engine, text


# ------------------------------------------------------------------
# Helper: run SQL and capture errors
# ------------------------------------------------------------------
def execute_sql(sql: str, db_uri: str):
    try:
        engine = create_engine(db_uri)
        with engine.connect() as conn:
            rows = conn.execute(text(sql)).fetchall()
        rows = [dict(r._mapping) for r in rows]
        return {"rows": rows}                # success
    except Exception as e:
        return {"error": str(e)}             # failure


# ------------------------------------------------------------------
# Main pipeline with single automatic retry
# ------------------------------------------------------------------
def process_question(question: str, db_uri: str, llm, max_retry: int = 1) -> dict:
    """
    1. Pick tables
    2. Build schema
    3. Ask LLM for SQL
    4. Execute SQL
    5. If DB error, ask LLM once more to fix it (bounded retry)
    Returns: {sql: str, results: list[dict]}  OR  {sql: str, error: str}
    """

    # ----- table discovery -----
    wide_db = SQLDatabase.from_uri(db_uri)
    all_table_names = wide_db.get_usable_table_names()
    relevant_tables = pick_tables(question, all_table_names, llm)   # <- fixed var

    # ----- schema text -----
    filtered_db = SQLDatabase.from_uri(db_uri, include_tables=relevant_tables)
    schema_text = get_schema_text(filtered_db, db_uri)

    # ----- first SQL generation -----
    sql = extract_sql_query(
        generate_sql_custom(question, schema_text, llm)
    )

    # ----- try executing -----
    result = execute_sql(sql, db_uri)

    # ----- automatic single retry if error -----
    if "error" in result and max_retry > 0:
        retry_prompt = (
            f"You generated this SQL:\n{sql}\n\n"
            f"It failed with this error:\n{result['error']}\n\n"
            f"Schema:\n{schema_text}\n\n"
            "Please correct the SQL. Output only SQL code."
        )
        fixed_sql = extract_sql_query(llm(retry_prompt))
        retry_out = execute_sql(fixed_sql, db_uri)

        # overwrite if second attempt succeeded (or keep final error)
        sql = fixed_sql
        result = retry_out

    # ----- build response -----
    if "rows" in result:
        return {"sql": sql, "results": result["rows"]}
    else:
        return {"sql": sql, "error": result["error"]}






























































































































































































































































































[DEBUG] Cypher generated:
MATCH (customer:Customer)-[:RELATED_TO]->(index:Index)
WHERE index.Country='Bhutan'
RETURN customer.Customer_Id AS CustomerId, customer.First_Name AS FirstName
ORDER BY customer.First_Name ASC
```
This Cypher query searches for customers by following the `RELATED_TO` relationship from the `Index` node and filters the result by the country property equal to 'Bhutan'. It then returns the `CustomerId` and `FirstName` properties of the matching `Customer` nodes in an ascending order by their `FirstName` property.
[ERROR] Cypher query failed: {code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input '```\nThis Cypher query searches for customers by following the `': expected 'FOREACH', ',', 'ORDER BY', 'CALL', 'CREATE', 'LOAD CSV', 'DELETE', 'DETACH', 'FINISH', 'INSERT', 'LIMIT', 'MATCH', 'MERGE', 'NODETACH', 'OFFSET', 'OPTIONAL', 'REMOVE', 'RETURN', 'SET', 'SKIP', 'UNION', 'UNWIND', 'USE', 'WITH' or <EOF> (line 5, column 1 (offset: 193))
"```"
^}
Answer: []


























[DEBUG] Cypher generated:

```cypher

MATCH (c:Customer)-[:RELATED_TO]->(i:Index)

WHERE i.Country = 'bhutan'

RETURN c.Customer_Id AS id, c.First_Name AS name

```

This query will return the Customer nodes that have a relationship `RELATED_TO` to an Index node with the property `Country` equal to 'bhutan'. The results will include the `Customer_Id` and `First_Name` properties of the Customer node.

[ERROR] Cypher query failed: {code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input '```cypher\nMATCH (c:Customer)-[:RELATED_TO]->(i:Index)\nWHERE i.Country = 'bhutan'\nRETURN c.Customer_Id AS id, c.First_Name AS name\n```': expected 'FOREACH', 'ALTER', 'ORDER BY', 'CALL', 'USING PERIODIC COMMIT', 'CREATE', 'LOAD CSV', 'START DATABASE', 'STOP DATABASE', 'DEALLOCATE', 'DELETE', 'DENY', 'DETACH', 'DROP', 'DRYRUN', 'FINISH', 'GRANT', 'INSERT', 'LIMIT', 'MATCH', 'MERGE', 'NODETACH', 'OFFSET', 'OPTIONAL', 'REALLOCATE', 'REMOVE', 'RENAME', 'RETURN', 'REVOKE', 'ENABLE SERVER', 'SET', 'SHOW', 'SKIP', 'TERMINATE', 'UNWIND', 'USE' or 'WITH' (line 1, column 1 (offset: 0))

"```cypher"

^}
 























ok lets do this functionality . create functions 
step 1 i want the user to like upload a csv file from CMD
step 2 the csv file gets converted into this GRAPH DB ( stored in GRAPH DB )
Step 3 i have a mistral model which runs locally it should dynamically know the schema of the GRAPH DB and make a cyper query according to the question asked by the user on the csv 
step 4 run the cypher query , fetch the results
step 5 . display the results 

import pandas as pd
from neo4j import GraphDatabase
from llama_cpp import Llama
 
# === Neo4j Configuration ===
NEO4J_URI = "bolt://localhost:7687"
NEO4J_USER = "neo4j"
NEO4J_PASSWORD = "your_password"  # Replace with your actual password
 
# === Load CSV ===
def load_csv(file_path):
    df = pd.read_csv(file_path)
    df.columns = [col.strip().replace(" ", "_") for col in df.columns]
    print("[INFO] CSV Loaded. Columns:", list(df.columns))
    return df
 
# === Infer Simple Schema ===
def infer_schema(df):
    node1, node2 = df.columns[0], df.columns[1]
    rel_prop = df.columns[2] if len(df.columns) > 2 else None
    return {
        "node1": node1,
        "node2": node2,
        "rel_type": "RELATED_TO",
        "rel_prop": rel_prop
    }
 
# === Insert Data into Neo4j ===
def insert_into_neo4j(df, schema):
    driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))
    with driver.session() as session:
        for _, row in df.iterrows():
            props = f"{{{schema['rel_prop']}: '{row[schema['rel_prop']]}'}}" if schema['rel_prop'] else ""
            cypher = f"""
            MERGE (a:{schema['node1']} {{name: $a_name}})
            MERGE (b:{schema['node2']} {{name: $b_name}})
            MERGE (a)-[:{schema['rel_type']} {props}]->(b)
            """
            session.run(
                cypher,
                a_name=str(row[schema['node1']]),
                b_name=str(row[schema['node2']])
            )
    print("[INFO] Data inserted into Neo4j.")
 
# === Prompt Builder for Mistral ===
def build_prompt(schema, question):
    return f"""You are a Cypher expert working with a Neo4j graph database.
Graph Schema:
(:{schema['node1']})-[:{schema['rel_type']}]->(:{schema['node2']})
Properties:
- {schema['node1']}: name
- {schema['node2']}: name
- {schema['rel_type']}: {schema['rel_prop']}
 
Examples:
Q: What did Alice buy?
A: MATCH (a:{schema['node1']} {{name: "Alice"}})-[:{schema['rel_type']}]->(b:{schema['node2']}) RETURN b.name
Q: {question}
A:"""
 
# === Query Mistral via llama-cpp ===
llm = Llama(
    model_path="mistral-7b-instruct-v0.2.Q4_K_M.gguf",
    n_ctx=2048,
    n_threads=6,
    verbose=True
)
 
def query_mistral(prompt):
    output = llm(prompt, max_tokens=200, stop=["\n\n", "\nQ:"], echo=False)
    return output["choices"][0]["text"].strip()
 
# === Execute Cypher Query ===
def run_cypher_query(cypher):
    driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))
    with driver.session() as session:
        result = session.run(cypher)
        return [record.values() for record in result]
 
# === Main ===
def main():
    csv_path = input("Enter full path of your CSV file (or just filename if it's in the same folder): ")
    df = load_csv(csv_path)
    schema = infer_schema(df)
    insert_into_neo4j(df, schema)
 
    while True:
        question = input("\nAsk a question (or type 'exit' to quit): ")
        if question.lower() == 'exit':
            break
        prompt = build_prompt(schema, question)
        print("\n[DEBUG] Prompt sent to Mistral:\n", prompt)
        cypher = query_mistral(prompt)
        print("\n[DEBUG] Cypher generated:\n", cypher)
        results = run_cypher_query(cypher)
        print("Answer:", results)
 
if __name__ == "__main__":
    main()










































































































































































































































Application bundle generation failed. [2.648 seconds]

▲ [WARNING] NG8103: The `*ngFor` directive was used in the template, but neither the `NgFor` directive nor the `CommonModule` was imported. Use Angular's built-in control flow @for or make sure that either the `NgFor` directive or the `CommonModule` is included in the `@Component.imports` array of this component. [plugin angular-compiler]

    src/app/app.component.html:5:10:
      5 │     <div *ngFor="let msg of messages">
        ╵           ~~~~~

  Error occurs in the template of component AppComponent.

    src/app/app.component.ts:13:15:
      13 │   templateUrl: './app.component.html',
         ╵                ~~~~~~~~~~~~~~~~~~~~~~


▲ [WARNING] NG8103: The `*ngIf` directive was used in the template, but neither the `NgIf` directive nor the `CommonModule` was imported. Use Angular's built-in control flow @if or make sure that either the `NgIf` directive or the `CommonModule` is included in the `@Component.imports` array of this component. [plugin angular-compiler]

    src/app/app.component.html:6:29:
      6 │       <div class="user-msg" *ngIf="msg.role === 'user'">You: {{ msg...
        ╵                              ~~~~

  Error occurs in the template of component AppComponent.

    src/app/app.component.ts:13:15:
      13 │   templateUrl: './app.component.html',
         ╵                ~~~~~~~~~~~~~~~~~~~~~~


▲ [WARNING] NG8103: The `*ngIf` directive was used in the template, but neither the `NgIf` directive nor the `CommonModule` was imported. Use Angular's built-in control flow @if or make sure that either the `NgIf` directive or the `CommonModule` is included in the `@Component.imports` array of this component. [plugin angular-compiler]

    src/app/app.component.html:8:28:
      8 │       <div class="bot-msg" *ngIf="msg.role === 'bot'">
        ╵                             ~~~~

  Error occurs in the template of component AppComponent.

    src/app/app.component.ts:13:15:
      13 │   templateUrl: './app.component.html',
         ╵                ~~~~~~~~~~~~~~~~~~~~~~


▲ [WARNING] NG8103: The `*ngIf` directive was used in the template, but neither the `NgIf` directive nor the `CommonModule` was imported. Use Angular's built-in control flow @if or make sure that either the `NgIf` directive or the `CommonModule` is included in the `@Component.imports` array of this component. [plugin angular-compiler]

    src/app/app.component.html:12:16:
      12 │         <table *ngIf="msg.results?.length">
         ╵                 ~~~~

  Error occurs in the template of component AppComponent.

    src/app/app.component.ts:13:15:
      13 │   templateUrl: './app.component.html',
         ╵                ~~~~~~~~~~~~~~~~~~~~~~


▲ [WARNING] NG8103: The `*ngFor` directive was used in the template, but neither the `NgFor` directive nor the `CommonModule` was imported. Use Angular's built-in control flow @for or make sure that either the `NgFor` directive or the `CommonModule` is included in the `@Component.imports` array of this component. [plugin angular-compiler]

    src/app/app.component.html:15:19:
      15 │               <th *ngFor="let key of getKeys(msg.results[0])">{{ k...
         ╵                    ~~~~~

  Error occurs in the template of component AppComponent.

    src/app/app.component.ts:13:15:
      13 │   templateUrl: './app.component.html',
         ╵                ~~~~~~~~~~~~~~~~~~~~~~


▲ [WARNING] NG8103: The `*ngFor` directive was used in the template, but neither the `NgFor` directive nor the `CommonModule` was imported. Use Angular's built-in control flow @for or make sure that either the `NgFor` directive or the `CommonModule` is included in the `@Component.imports` array of this component. [plugin angular-compiler]

    src/app/app.component.html:19:17:
      19 │             <tr *ngFor="let row of msg.results">
         ╵                  ~~~~~

  Error occurs in the template of component AppComponent.

    src/app/app.component.ts:13:15:
      13 │   templateUrl: './app.component.html',
         ╵                ~~~~~~~~~~~~~~~~~~~~~~


▲ [WARNING] NG8103: The `*ngFor` directive was used in the template, but neither the `NgFor` directive nor the `CommonModule` was imported. Use Angular's built-in control flow @for or make sure that either the `NgFor` directive or the `CommonModule` is included in the `@Component.imports` array of this component. [plugin angular-compiler]

    src/app/app.component.html:20:19:
      20 │               <td *ngFor="let key of getKeys(row)">{{ row[key] }}<...
         ╵                    ~~~~~

  Error occurs in the template of component AppComponent.

    src/app/app.component.ts:13:15:
      13 │   templateUrl: './app.component.html',
         ╵                ~~~~~~~~~~~~~~~~~~~~~~


X [ERROR] NG8002: Can't bind to 'ngModel' since it isn't a known property of 'input'. [plugin angular-compiler]

    src/app/app.component.html:29:11:
      29 │     <input [(ngModel)]="userInput" placeholder="Ask your question....
         ╵            ~~~~~~~~~~~~~~~~~~~~~~~

  Error occurs in the template of component AppComponent.

    src/app/app.component.ts:13:15:
      13 │   templateUrl: './app.component.html',
         ╵                ~~~~~~~~~~~~~~~~~~~~~~


Watch mode enabled. Watching for file changes...


































































User Query: give me eon orders from 9am to 12pm on 1st june 2015
Llama.generate: 1 prefix-match hit, remaining 788 prompt tokens to eval
llama_perf_context_print:        load time =    1240.90 ms
llama_perf_context_print: prompt eval time =   80236.62 ms /   788 tokens (  101.82 ms per token,     9.82 tokens per second)
llama_perf_context_print:        eval time =   16153.41 ms /    99 runs   (  163.17 ms per token,     6.13 tokens per second)
llama_perf_context_print:       total time =   96451.71 ms /   887 tokens


User Query: give me the orders of eon from 9am -12pm on 1st june2015
Llama.generate: 761 prefix-match hit, remaining 28 prompt tokens to eval
llama_perf_context_print:        load time =    1240.90 ms
llama_perf_context_print: prompt eval time =    2154.85 ms /    28 tokens (   76.96 ms per token,    12.99 tokens per second)
llama_perf_context_print:        eval time =   12370.32 ms /    92 runs   (  134.46 ms per token,     7.44 tokens per second)
llama_perf_context_print:       total time =   14563.50 ms /   120 tokens





















select DISTINCT si.order_no ,si.item_no ,ii.action as 'Order Action',oo.order_type as 'Order Type',sca.account_no as 'BAN',sca.account_name as 'CustName',
itc.description ,psp.sub_profile_desc, si.circuit_id as 'FroId', scp.cpi_status_code as 'Circuit Status',     	
case when sva.cust_site_id != 'null' then  aa.address + '  '+ aa.city + ' '+ aa.state + ' '+ aa.country else '' end as 'Customer Prem Address A',  
case when sva.cust_site_id != 'null' then  ca.country_name else '' end as 'A customer prem country',  
case when svz.cust_site_id != 'null' then  az.address + '  '+ az.city + ' '+ az.state + ' '+ az.country else '' end as 'Customer Prem Address Z',  
case when svz.cust_site_id != 'null' then  cz.country_name else '' end as 'Z customer prem country',  ii.create_date as 'Created Date'
from orders oo join sonet_item si on oo.id=si.order_no  
join improv_item ii on ii.id=si.id  
join sonet_vendor_interface sva on sva.side='A' and sva.item_id=si.id  
left outer join site sa on sva.cust_site_id=sa.site_id  
left outer join address aa on sa.address_id=aa.address_id  
join sonet_vendor_interface svz on svz.side='Z'and svz.item_id=si.id  
left outer join site sz on svz.cust_site_id=sz.site_id  
left outer join address az on sz.address_id=az.address_id  
left outer join country ca on ca.country_alpha3_code=aa.country  
left outer join country cz on cz.country_alpha3_code=az.country , 
profile_sub_profile psp,improv_item_catalog itc,sonet_customer_account sca,sonet_cpi scp  
where si.sub_profile_code =psp.id and sca.account_no=oo.account_no and si.circuit_id=scp.circuit_id and itc.item_type=psp.item_type  and
ii.create_date between '2024/10/01' and '2024/10/24';



























































User Query: hello i want orders which are cancelled
Llama.generate: 676 prefix-match hit, remaining 12 prompt tokens to eval
llama_perf_context_print:        load time =   61542.72 ms
llama_perf_context_print: prompt eval time =     985.22 ms /    12 tokens (   82.10 ms per token,    12.18 tokens per second)
llama_perf_context_print:        eval time =    9462.99 ms /    66 runs   (  143.38 ms per token,     6.97 tokens per second)
llama_perf_context_print:       total time =   10473.24 ms /    78 tokens

LLM Response (raw):
{
  "source_system": "EON",
  "order_type": "ALL",
  "order_status": "cancelled",
  "order_action": "ALL",
  "start_date": "none",
  "end_date": "now"
}

llama_perf_context_print:       total time =   10473.24 ms /    78 tokens

LLM Response (raw):
{
  "source_system": "EON",
  "order_type": "ALL",
  "order_status": "cancelled",
  "order_action": "ALL",
  "start_date": "none",
  "end_date": "now"
}

LLM Response (raw):
{
  "source_system": "EON",
  "order_type": "ALL",
  "order_status": "cancelled",
  "order_action": "ALL",
  "start_date": "none",
  "end_date": "now"
}

  "source_system": "EON",
  "order_type": "ALL",
  "order_status": "cancelled",
  "order_action": "ALL",
  "start_date": "none",
  "end_date": "now"
}

  "order_type": "ALL",
  "order_status": "cancelled",
  "order_action": "ALL",
  "start_date": "none",
  "end_date": "now"
}

  "order_action": "ALL",
  "start_date": "none",
  "end_date": "now"
}

  "start_date": "none",
  "end_date": "now"
}

  "end_date": "now"
}

}


































PS C:\Users\AD54619\Text2Sql\approach1> python new.py
⏳ Loading Mistral 7B model via llama.cpp...
Traceback (most recent call last):
  File "C:\Users\AD54619\Text2Sql\approach1\new.py", line 58, in <module>
    llm = MistralLLM(model_path=MODEL_PATH)
  File "C:\Users\AD54619\Text2Sql\approach1\new.py", line 29, in __init__
    self.verbose = verbose  # ✅ Fix: Add this line
    ^^^^^^^^^^^^
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\pydantic\main.py", line 991, in __setattr__
    setattr_handler(self, name, value)  # call here to not memo on possibly unknown fields
    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\pydantic\main.py", line 99, in _model_field_setattr_handler  
    model.__pydantic_fields_set__.add(name)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\AD54619\Text2Sql\approach1\new.py", line 53, in __getattr__
    raise AttributeError(f"{type(self).__name__!r} object has no attribute {name!r}")
AttributeError: 'MistralLLM' object has no attribute '__pydantic_fields_set__'. Did you mean: '__pydantic_fields__'? 




































🧠 Step: get me list of all customers
Traceback (most recent call last):
  File "C:\Users\AD54619\Text2Sql\approach1\new.py", line 85, in <module>
    chat()
    ~~~~^^
  File "C:\Users\AD54619\Text2Sql\approach1\new.py", line 81, in chat
    for step in agent_executor.stream({"messages": [HumanMessage(content=user_input)]}, stream_mode="values"):
                ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\langgraph\pregel\__init__.py", line 2340, in stream
    for _ in runner.tick(
             ~~~~~~~~~~~^
        loop.tasks.values(),
        ^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
        get_waiter=get_waiter,
        ^^^^^^^^^^^^^^^^^^^^^^
    ):
    ^
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\langgraph\pregel\runner.py", line 158, in tick
    run_with_retry(
    ~~~~~~~~~~~~~~^
        t,
        ^^
    ...<11 lines>...
        },
        ^^
    )
    ^
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\langgraph\pregel\retry.py", line 40, in run_with_retry       
    return task.proc.invoke(task.input, config)
           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\langgraph\utils\runnable.py", line 606, in invoke
    input = step.invoke(input, config, **kwargs)
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\langgraph\utils\runnable.py", line 363, in invoke
    ret = context.run(self.func, *args, **kwargs)
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\langgraph\prebuilt\chat_agent_executor.py", line 745, in call_model
    response = cast(AIMessage, model_runnable.invoke(state, config))
                               ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\langchain_core\runnables\base.py", line 3025, in invoke      
    input = context.run(step.invoke, input, config)
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\langchain_core\language_models\chat_models.py", line 307, in invoke
    self.generate_prompt(
    ~~~~~~~~~~~~~~~~~~~~^
        [self._convert_input(input)],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<6 lines>...
        **kwargs,
        ^^^^^^^^^
    ).generations[0][0],
    ^
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\langchain_core\language_models\chat_models.py", line 843, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\langchain_core\language_models\chat_models.py", line 664, in generate
    self.verbose,
    ^^^^^^^^^^^^
  File "C:\Users\AD54619\Text2Sql\approach1\new.py", line 51, in __getattr__
    raise AttributeError(f"{type(self).__name__!r} object has no attribute {name!r}")
AttributeError: 'MistralLLM' object has no attribute 'verbose'
During task with name 'agent' and id '05dbd901-99e5-f529-6d83-b3f81d8644da'







































🧠 Step: list all customers
Traceback (most recent call last):
  File "C:\Users\AD54619\Text2Sql\approach1\new.py", line 82, in <module>
    chat()
    ~~~~^^
  File "C:\Users\AD54619\Text2Sql\approach1\new.py", line 78, in chat
    for step in agent_executor.stream({"messages": [HumanMessage(content=user_input)]}, stream_mode="values"):
                ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\langgraph\pregel\__init__.py", line 2340, in stream
    for _ in runner.tick(
             ~~~~~~~~~~~^
        loop.tasks.values(),
        ^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
        get_waiter=get_waiter,
        ^^^^^^^^^^^^^^^^^^^^^^
    ):
    ^
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\langgraph\pregel\runner.py", line 158, in tick
    run_with_retry(
    ~~~~~~~~~~~~~~^
        t,
        ^^
    ...<11 lines>...
        },
        ^^
    )
    ^
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\langgraph\pregel\retry.py", line 40, in run_with_retry       
    return task.proc.invoke(task.input, config)
           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\langgraph\utils\runnable.py", line 606, in invoke
    input = step.invoke(input, config, **kwargs)
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\langgraph\utils\runnable.py", line 363, in invoke
    ret = context.run(self.func, *args, **kwargs)
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\langgraph\prebuilt\chat_agent_executor.py", line 745, in call_model
    response = cast(AIMessage, model_runnable.invoke(state, config))
                               ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\langchain_core\runnables\base.py", line 3025, in invoke      
    input = context.run(step.invoke, input, config)
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\langchain_core\language_models\chat_models.py", line 307, in invoke
    self.generate_prompt(
    ~~~~~~~~~~~~~~~~~~~~^
        [self._convert_input(input)],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<6 lines>...
        **kwargs,
        ^^^^^^^^^
    ).generations[0][0],
    ^
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\langchain_core\language_models\chat_models.py", line 843, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\langchain_core\language_models\chat_models.py", line 663, in generate
    self.callbacks,
    ^^^^^^^^^^^^^^
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\pydantic\main.py", line 984, in __getattr__
    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')
AttributeError: 'MistralLLM' object has no attribute 'callbacks'
During task with name 'agent' and id 'd47a6d5a-987a-ea77-1805-3ebbd8e47d2d'
































be provided when using hosted LangSmith API
  warnings.warn(
Traceback (most recent call last):
  File "C:\Users\AD54619\Text2Sql\approach1\new.py", line 62, in <module>
    agent_executor = create_react_agent(llm, tools, prompt=system_prompt)
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\langgraph\prebuilt\chat_agent_executor.py", line 160, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\langgraph\prebuilt\chat_agent_executor.py", line 691, in create_react_agent
    model = cast(BaseChatModel, model).bind_tools(tool_classes)
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1174, in
 bind_tools
    raise NotImplementedError
NotImplementedError
PS C:\Users\AD54619\Text2Sql\approach1> 























Guessed chat format: mistral-instruct
Traceback (most recent call last):
  File "C:\Users\AD54619\Text2Sql\approach1\new.py", line 50, in <module>
    llm = MistralLLM(model_path=MODEL_PATH)
  File "C:\Users\AD54619\Text2Sql\approach1\new.py", line 31, in __init__
    self.llama = Llama(
    ^^^^^^^^^^
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\pydantic\main.py", line 990, in __setattr__
    elif (setattr_handler := self._setattr_handler(name, value)) is not None:
                             ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\pydantic\main.py", line 1037, in _setattr_handler
    raise ValueError(f'"{cls.__name__}" object has no field "{name}"')
ValueError: "MistralLLM" object has no field "llama"






















C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\langsmith\client.py:278: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API
  warnings.warn(
Traceback (most recent call last):
  File "C:\Users\AD54619\Text2Sql\approach1\new.py", line 54, in <module>
    agent_executor = create_react_agent(llm, tools, prompt=system_prompt)
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\langgraph\prebuilt\chat_agent_executor.py", line 160, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\langgraph\prebuilt\chat_agent_executor.py", line 691, in create_react_agent
    model = cast(BaseChatModel, model).bind_tools(tool_classes)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'MistralLLM' object has no attribute 'bind_tools'
PS C:\Users\AD54619\Text2Sql\approach1> python new.py
Traceback (most recent call last):
  File "C:\Users\AD54619\Text2Sql\approach1\new.py", line 46, in <module>
    llm = MistralLLM(model_path=MODEL_PATH)
TypeError: Can't instantiate abstract class MistralLLM without an implementation for abstract methods '_generate', '_llm_type'
PS C:\Users\AD54619\Text2Sql\a























Traceback (most recent call last):
  File "C:\Users\AD54619\Text2Sql\approach1\new.py", line 54, in <module>
    agent_executor = create_react_agent(llm, tools, prompt=system_prompt)
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\langgraph\prebuilt\chat_agent_executor.py", line 160, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\langgraph\prebuilt\chat_agent_executor.py", line 691, in create_react_agent
    model = cast(BaseChatModel, model).bind_tools(tool_classes)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'MistralLLM' object has no attribute 'bind_tools'






Guessed chat format: mistral-instruct
✅ Model loaded!
Traceback (most recent call last):
  File "C:\Users\AD54619\Text2Sql\approach1\new.py", line 40, in <module>
    toolkit = SQLDatabaseToolkit(db=db, llm=llm)
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\pydantic\main.py", line 243, in __init__
    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
pydantic_core._pydantic_core.ValidationError: 1 validation error for SQLDatabaseToolkit
llm
  Input should be a valid dictionary or instance of BaseLanguageModel [type=model_type, input_value=<__main__.MistralLLM object at 0x0000013CEB299940>, input_type=MistralLLM]
    For further information visit https://errors.pydantic.dev/2.11/v/model_type

















POST https://localhost:5000/api/query
Error: write EPROTO 54290880:error:100000f7:SSL routines:OPENSSL_internal:WRONG_VERSION_NUMBER:..\..\..\..\src\third_party\boringssl\src\ssl\tls_record.cc:231:
Request Headers
Content-Type: application/json
User-Agent: PostmanRuntime/7.43.0
Accept: */*
Postman-Token: 90760198-d809-4294-951b-93166c45efd1
Host: localhost:5000
Accept-Encoding: gzip, deflate, br
Connection: keep-alive
Request Body






















User Question: get me employee details who belong to department engineering
Llama.generate: 201 prefix-match hit, remaining 23 prompt tokens to eval
llama_perf_context_print:        load time =   19596.31 ms
llama_perf_context_print: prompt eval time =    1581.68 ms /    23 tokens (   68.77 ms per token,    14.54 tokens per second)
llama_perf_context_print:        eval time =    8347.60 ms /    64 runs   (  130.43 ms per token,     7.67 tokens per second)
llama_perf_context_print:       total time =    9951.81 ms /    87 tokens

Final SQL Query:
```sql
SELECT employees.id, employees.name, employees.age, departments.department_name
FROM employees
JOIN departments ON employees.department = departments.department_name
```


❌ Error executing query: (pymysql.err.ProgrammingError) (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '```sql\nSELECT employees.id, employees.name, employees.age, departments.departmen' at line 1")
[SQL: ```sql
SELECT employees.id, employees.name, employees.age, departments.department_name
FROM employees
JOIN departments ON employees.department = departments.department_name
WHERE departments.department_name = 'engineering'
```]
(Background on this error at: https://sqlalche.me/e/20/f405)

User Question:





















PS C:\Users\AD54619\Text2Sql> python gemma_sql.py
⏳ Loading Gemma-2B model (HuggingFace style)...
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  3.36it/s]
✅ Model loaded!
Device set to use cpu

🔹Gemma-2B Chat w/ MySQL using custom prompt (no chain-of-thought).

Type 'exit' or 'quit' to stop.

User Question: fetch details of employee belonging to sales department
C:\Users\AD54619\Text2Sql\gemma_sql.py:126: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.
  result = llm(prompt)

Final SQL Query:
Generate an SQL query strictly based on the schema provided.

Schema:
Table: departments
  - id (INTEGER)
  - department_name (TEXT)
  - location (TEXT)

Table: employees
  - id (INTEGER)
  - name (TEXT)
  - age (INTEGER)
  - department (TEXT)
  - salary (INTEGER)

Question:
fetch details of employee belonging to sales department

Only output SQL code. Do not output any explanation or additional text.
SQL:

SELECT
  e.id,
  e.name,
  e.age,
  e.salary,
  d.department_name
FROM
  employees e
  LEFT JOIN departments d ON e.department = d.id
WHERE
  d.department_name ='sales'

Output:
SELECT e.id, e.name, e.age, e.salary, d.department_name FROM employees e LEFT JOIN departments d ON e.department = d.id WHERE d.department_name ='sales'


❌ Error executing query: (pymysql.err.ProgrammingError) (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'Generate an SQL query strictly based on the schema provided.\n\nSchema:\nTable: dep' at line 1")
[SQL: Generate an SQL query strictly based on the schema provided.

Schema:
Table: departments
  - id (INTEGER)
  - department_name (TEXT)
  - location (TEXT)

Table: employees
  - id (INTEGER)
  - name (TEXT)
  - age (INTEGER)
  - department (TEXT)
  - salary (INTEGER)

Question:
fetch details of employee belonging to sales department

Only output SQL code. Do not output any explanation or additional text.
SQL:

SELECT
  e.id,
  e.name,
  e.age,
  e.salary,
  d.department_name
FROM
  employees e
  LEFT JOIN departments d ON e.department = d.id
WHERE
  d.department_name ='sales'

Output:
SELECT e.id, e.name, e.age, e.salary, d.department_name FROM employees e LEFT JOIN departments d ON e.department = d.id WHERE d.department_name ='sales']
(Background on this error at: https://sqlalche.me/e/20/f405)

User Question: get employees earning more than 20000

Final SQL Query:
SELECT *
FROM employees
WHERE salary > 20000;

DB Results:
(101, 'John Smith', 35, '1', 85000)
(102, 'Sarah Johnson', 42, '2', 78000)
(103, 'Michael Brown', 28, '1', 72000)
(104, 'Jessica Davis', 31, '3', 90000)
(105, 'Robert Wilson', 45, '4', 65000)
(106, 'Lisa Anderson', 38, '5', 92000)
(107, 'David Miller', 27, '1', 68000)
(108, 'Jennifer Garcia', 33, '2', 71000)
(109, 'Thomas Martinez', 41, '3', 86000)
(110, 'Emily Rodriguez', 29, '5', 81000)

User Question: get employee whose name begins with letter R 

Final SQL Query:
Generate an SQL query strictly based on the schema provided.

Schema:
Table: departments
  - id (INTEGER)
  - department_name (TEXT)
  - location (TEXT)

Table: employees
  - id (INTEGER)
  - name (TEXT)
  - age (INTEGER)
  - department (TEXT)
  - salary (INTEGER)

Question:
get employee whose name begins with letter R

Only output SQL code. Do not output any explanation or additional text.
SQL:


❌ Error executing query: (pymysql.err.ProgrammingError) (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'Generate an SQL query strictly based on the schema provided.\n\nSchema:\nTable: dep' at line 1")
[SQL: Generate an SQL query strictly based on the schema provided.

Schema:
Table: departments
  - id (INTEGER)
  - department_name (TEXT)
  - location (TEXT)

Table: employees
  - id (INTEGER)
  - name (TEXT)
  - age (INTEGER)
  - department (TEXT)
  - salary (INTEGER)

Question:
get employee whose name begins with letter R

Only output SQL code. Do not output any explanation or additional text.
SQL:]
(Background on this error at: https://sqlalche.me/e/20/f405)

User Question: get employee who belongs to finance department

Final SQL Query:
Generate an SQL query strictly based on the schema provided.

Schema:
Table: departments
  - id (INTEGER)
  - department_name (TEXT)
  - location (TEXT)

Table: employees
  - id (INTEGER)
  - name (TEXT)
  - age (INTEGER)
  - department (TEXT)
  - salary (INTEGER)

Question:
get employee who belongs to finance department

Only output SQL code. Do not output any explanation or additional text.
SQL:


❌ Error executing query: (pymysql.err.ProgrammingError) (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'Generate an SQL query strictly based on the schema provided.\n\nSchema:\nTable: dep' at line 1")
[SQL: Generate an SQL query strictly based on the schema provided.

Schema:
Table: departments
  - id (INTEGER)
  - department_name (TEXT)
  - location (TEXT)

Table: employees
  - id (INTEGER)
  - name (TEXT)
  - age (INTEGER)
  - department (TEXT)
  - salary (INTEGER)

Question:
get employee who belongs to finance department

Only output SQL code. Do not output any explanation or additional text.
SQL:]
(Background on this error at: https://sqlalche.me/e/20/f405)

User Question: get employee who earn more than 20000 incomme

Final SQL Query:
Generate an SQL query strictly based on the schema provided.

Schema:
Table: departments
  - id (INTEGER)
  - department_name (TEXT)
  - location (TEXT)

Table: employees
  - id (INTEGER)
  - name (TEXT)
  - age (INTEGER)
  - department (TEXT)
  - salary (INTEGER)

Question:
get employee who earn more than 20000 incomme

Only output SQL code. Do not output any explanation or additional text.
SQL:

SELECT *
FROM employees
WHERE salary > 20000


❌ Error executing query: (pymysql.err.ProgrammingError) (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'Generate an SQL query strictly based on the schema provided.\n\nSchema:\nTable: dep' at line 1")
[SQL: Generate an SQL query strictly based on the schema provided.

Schema:
Table: departments
  - id (INTEGER)
  - department_name (TEXT)
  - location (TEXT)

Table: employees
  - id (INTEGER)
  - name (TEXT)
  - age (INTEGER)
  - department (TEXT)
  - salary (INTEGER)

Question:
get employee who earn more than 20000 incomme

Only output SQL code. Do not output any explanation or additional text.
SQL:

SELECT *
FROM employees
WHERE salary > 20000]
(Background on this error at: https://sqlalche.me/e/20/f405)

User Question:































Type 'exit' or 'quit' to stop.

User Question: fetch all employees whoose salary is more than 50000
C:\Users\AD54619\Text2Sql\simple_tiny.py:94: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.
  result = llm(prompt)

Generated SQL Query:
Generate an SQL query strictly based on the schema provided.

Schema:
Table: employees
  - id (INTEGER)
  - name (TEXT)
  - age (INTEGER)
  - department (TEXT)
  - salary (INTEGER)

Question:
fetch all employees whoose salary is more than 50000

Only output SQL code. Do not output any explanation or additional text.
SQL:
SELECT * FROM employees WHERE salary > 50000;

Explanation:
This query fetches all employees whose salary is more than 50000.

I hope this helps! Let me know if you have any further questions.


❌ Error executing query: Not an executable object: 'Generate an SQL query strictly based on the schema provided.\n\nSchema:\nTable: employees\n  - id (INTEGER)\n  - name (TEXT)\n  - age (INTEGER)\n  - department (TEXT)\n  - salary (INTEGER)\n\nQuestion:\nfetch all employees whoose salary is more than 50000\n\nOnly output SQL code. Do not output any explanation or additional text.\nSQL:\nSELECT * FROM employees WHERE salary > 50000;\n\nExplanation:\nThis query fetches all employees whose salary is more than 50000.\n\nI hope this helps! Let me know if you have any further questions.'

User Question:




























KeyboardInterrupt
PS C:\Users\AD54619\Text2Sql> python simple_tiny.py
⏳ Loading TinyLlama model (HuggingFace style)...
✅ Model loaded!
Device set to use cpu

🔹TinyLlama Chat w/ MySQL using custom prompt (no chain-of-thought).

Type 'exit' or 'quit' to stop.

User Question: give me employees whoose salary is more than 50000
C:\Users\AD54619\Text2Sql\simple_tiny.py:84: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.
  result = llm(prompt)

Generated SQL Query:
Generate an SQL query strictly based on the schema provided.

Schema:
Table: employees
  - [Error retrieving columns]

Question:
give me employees whoose salary is more than 50000

Only output SQL code. Do not output any explanation or additional text.
SQL:
SELECT * FROM employees
WHERE salary > 50000;


❌ Error executing query: Not an executable object: 'Generate an SQL query strictly based on the schema provided.\n\nSchema:\nTable: employees\n  - [Error retrieving columns]\n\nQuestion:\ngive me employees whoose salary is more than 50000\n\nOnly output SQL code. Do not output any explanation or additional text.\nSQL:\nSELECT * FROM employees\nWHERE salary > 50000;'

User Question:
















PS C:\Users\AD54619\Text2Sql> python better_tiny.py
⏳ Loading TinyLlama model (HuggingFace style)...
✅ Model loaded!
Device set to use cpu

🔹TinyLlama Chat w/ MySQL using LangChain.

Type 'exit' or 'quit' to stop.

[DEBUG] Table Names: ['departments', 'employees']
User Question: which employees belong to finance department
[DEBUG] Using these tables: ['employees']
Traceback (most recent call last):
  File "C:\Users\AD54619\Text2Sql\better_tiny.py", line 119, in <module>
    main()
    ~~~~^^
  File "C:\Users\AD54619\Text2Sql\better_tiny.py", line 103, in main
    chain = create_sql_query_chain(
        llm=llm,
        db=filtered_db,
        prompt=custom_prompt
    )
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\langchain\chains\sql_database\query.py", line 122, in create_sql_query_chain  
    raise ValueError(
    ...<3 lines>...
    )
ValueError: Prompt must have input variables: 'input', 'top_k', 'table_info'. Received prompt with input variables: ['question']. Full prompt:

input_variables=['question'] input_types={} partial_variables={} template='Generate a valid MySQL query for the following question:\n{question}\n\nReturn ONLY the SQL query. No extra explanation or examples.'


























S C:\Users\AD54619\Text2Sql> python better_tiny.py
⏳ Loading TinyLlama model (HuggingFace style)...
✅ Model loaded!
Device set to use cpu

🔹 TinyLlama MySQL Demo (Raw DB results only). Type 'exit' or 'quit' to stop.

Traceback (most recent call last):
  File "C:\Users\AD54619\Text2Sql\better_tiny.py", line 115, in <module>
    main()
    ~~~~^^
  File "C:\Users\AD54619\Text2Sql\better_tiny.py", line 84, in main
    columns = db.get_table_info(tbl)
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\langchain_community\utilities\sql_database.py", line 322, in get_table_info   
    raise ValueError(f"table_names {missing_tables} not found in database")
ValueError: table_names {'a', 't', 'p', 'e', 'n', 'm', 'd', 's', 'r'} not found in database























User Question: employee name whose salary is more than 50000
[DEBUG] Using tables: ['departments', 'employees']
[chain/start] [chain:RunnableSequence] Entering Chain run with input:
{
  "input": "employee name whose salary is more than 50000"
}
[chain/start] [chain:RunnableSequence > chain:RunnableAssign<input,table_info>] Entering Chain run with input:
{
  "input": "employee name whose salary is more than 50000"
}
[chain/start] [chain:RunnableSequence > chain:RunnableAssign<input,table_info> > chain:RunnableParallel<input,table_info>] Entering Chain run with input:
{
  "input": "employee name whose salary is more than 50000"
}
[chain/start] [chain:RunnableSequence > chain:RunnableAssign<input,table_info> > chain:RunnableParallel<input,table_info> > chain:RunnableLambda] Entering Chain run with input:
{
  "input": "employee name whose salary is more than 50000"
}
[chain/start] [chain:RunnableSequence > chain:RunnableAssign<input,table_info> > chain:RunnableParallel<input,table_info> > chain:RunnableLambda] Entering Chain run with input:
{
  "input": "employee name whose salary is more than 50000"
}
[chain/end] [chain:RunnableSequence > chain:RunnableAssign<input,table_info> > chain:RunnableParallel<input,table_info> > chain:RunnableLambda] [8ms] Exiting Chain run with output:
{
  "output": "\nCREATE TABLE departments (\n\tid INTEGER NOT NULL, \n\tdepartment_name TEXT NOT NULL, \n\tlocation TEXT, \n\tPRIMARY KEY (id)\n)COLLATE utf8mb4_0900_ai_ci ENGINE=InnoDB DEFAULT CHARSET=utf8mb4\n\n/*\n3 rows from departments table:\nid\tdepartment_name\tlocation\n1\tEngineering\tNew York\n2\tMarketing\tChicago\n3\tFinance\tBoston\n*/\n\n\nCREATE TABLE employees (\n\tid INTEGER NOT NULL, \n\tname TEXT NOT NULL, \n\tage INTEGER, \n\tdepartment TEXT, \n\tsalary INTEGER, \n\tPRIMARY KEY (id)\n)COLLATE utf8mb4_0900_ai_ci ENGINE=InnoDB DEFAULT CHARSET=utf8mb4\n\n/*\n3 rows from employees table:\nid\tname\tage\tdepartment\tsalary\n101\tJohn Smith\t35\t1\t85000\n102\tSarah Johnson\t42\t2\t78000\n103\tMichael Brown\t28\t1\t72000\n*/"
}
[chain/error] [chain:RunnableSequence > chain:RunnableAssign<input,table_info> > chain:RunnableParallel<input,table_info> > chain:RunnableLambda] [57ms] Chain run errored with error:
"KeyError('question')Traceback (most recent call last):\n\n\n  File \"C:\\Users\\AD54619\\Text2Sql\\virtualen\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 1925, in _call_with_config\n    context.run(\n    ~~~~~~~~~~~^\n        call_func_with_variable_args,  # type: ignore[arg-type]\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<4 lines>...\n        **kwargs,\n        ^^^^^^^^^\n    ),\n    ^\n\n\n  File \"C:\\Users\\AD54619\\Text2Sql\\virtualen\\Lib\\site-packages\\langchain_core\\runnables\\config.py\", line 430, in call_func_with_variable_args\n    return func(input, **kwargs)  # type: ignore[call-arg]\n\n\n  File \"C:\\Users\\AD54619\\Text2Sql\\virtualen\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 4573, in _invoke\n    output = call_func_with_variable_args(\n        self.func, input, config, run_manager, **kwargs\n    )\n\n\n  File \"C:\\Users\\AD54619\\Text2Sql\\virtualen\\Lib\\site-packages\\langchain_core\\runnables\\config.py\", line 430, in call_func_with_variable_args\n    return func(input, **kwargs)  # type: ignore[call-arg]\n\n\n  File \"C:\\Users\\AD54619\\Text2Sql\\virtualen\\Lib\\site-packages\\langchain\\chains\\sql_database\\query.py\", line 131, in <lambda>\n    \"input\": lambda x: x[\"question\"] + \"\\nSQLQuery: \",\n                       ~^^^^^^^^^^^^\n\n\nKeyError: 'question'"
[chain/error] [chain:RunnableSequence > chain:RunnableAssign<input,table_info> > chain:RunnableParallel<input,table_info>] [94ms] Chain run errored with error:
"KeyError('question')Traceback (most recent call last):\n\n\n  File \"C:\\Users\\AD54619\\Text2Sql\\virtualen\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3728, in invoke\n    output = {key: future.result() for key, future in zip(steps, futures)}\n             
      ~~~~~~~~~~~~~^^\n\n\n  File \"C:\\Users\\AD54619\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py\", line 456, in result\n    return self.__get_result()\n           ~~~~~~~~~~~~~~~~~^^\n\n\n  File \"C:\\Users\\AD54619\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n\n\n  File \"C:\\Users\\AD54619\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\thread.py\", line 59, in run\n    result = self.fn(*self.args, **self.kwargs)\n\n\n  File \"C:\\Users\\AD54619\\Text2Sql\\virtualen\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3712, in _invoke_step\n    return context.run(\n           ~~~~~~~~~~~^\n        step.invoke,\n        ^^^^^^^^^^^^\n        input,\n        ^^^^^^\n        child_config,\n        ^^^^^^^^^^^^^\n    )\n    ^\n\n\n  File \"C:\\Users\\AD54619\\Text2Sql\\virtualen\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 4719, in invoke\n    return self._call_with_config(\n           ~~~~~~~~~~~~~~~~~~~~~~^\n        self._invoke,\n        ^^^^^^^^^^^^^\n    ...<2 lines>...\n        **kwargs,\n        ^^^^^^^^^\n    )\n    ^\n\n\n  File \"C:\\Users\\AD54619\\Text2Sql\\virtualen\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 1925, in _call_with_config\n    context.run(\n    ~~~~~~~~~~~^\n        call_func_with_variable_args,  # type: ignore[arg-type]\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<4 lines>...\n        **kwargs,\n        ^^^^^^^^^\n    ),\n    ^\n\n\n  File \"C:\\Users\\AD54619\\Text2Sql\\virtualen\\Lib\\site-packages\\langchain_core\\runnables\\config.py\", line 430, in call_func_with_variable_args\n    return func(input, **kwargs)  # type: ignore[call-arg]\n\n\n  File \"C:\\Users\\AD54619\\Text2Sql\\virtualen\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 4573, in _invoke\n    output = call_func_with_variable_args(\n        self.func, input, config, run_manager, **kwargs\n    )\n\n\n  File \"C:\\Users\\AD54619\\Text2Sql\\virtualen\\Lib\\site-packages\\langchain_core\\runnables\\config.py\", line 430, in call_func_with_variable_args\n    return func(input, **kwargs)  # type: ignore[call-arg]\n\n\n  File \"C:\\Users\\AD54619\\Text2Sql\\virtualen\\Lib\\site-packages\\langchain\\chains\\sql_database\\query.py\", line 131, in <lambda>\n    \"input\": lambda x: x[\"question\"] + \"\\nSQLQuery: \",\n                       ~^^^^^^^^^^^^\n\n\nKeyError: 'question'"
[chain/error] [chain:RunnableSequence > chain:RunnableAssign<input,table_info>] [116ms] Chain run errored with error:
"KeyError('question')Traceback (most recent call last):\n\n\n  File \"C:\\Users\\AD54619\\Text2Sql\\virtualen\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 1925, in _call_with_config\n    context.run(\n    ~~~~~~~~~~~^\n        call_func_with_variable_args,  # type: ignore[arg-type]\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<4 lines>...\n        **kwargs,\n        ^^^^^^^^^\n    ),\n    ^\n\n\n  File \"C:\\Users\\AD54619\\Text2Sql\\virtualen\\Lib\\site-packages\\langchain_core\\runnables\\config.py\", line 430, in call_func_with_variable_args\n    return func(input, **kwargs)  # type: ignore[call-arg]\n\n\n  File \"C:\\Users\\AD54619\\Text2Sql\\virtualen\\Lib\\site-packages\\langchain_core\\runnables\\passthrough.py\", line 483, in _invoke\n    **self.mapper.invoke(\n      ~~~~~~~~~~~~~~~~~~^\n        input,\n        ^^^^^^\n        patch_config(config, callbacks=run_manager.get_child()),\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        **kwargs,\n        ^^^^^^^^^\n    ),\n    ^\n\n\n  File \"C:\\Users\\AD54619\\Text2Sql\\virtualen\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3728, in invoke\n    output = {key: future.result() for key, future in zip(steps, futures)}\n                   ~~~~~~~~~~~~~^^\n\n\n  File \"C:\\Users\\AD54619\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py\", line 456, in result\n    return self.__get_result()\n           ~~~~~~~~~~~~~~~~~^^\n\n\n  File \"C:\\Users\\AD54619\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n\n\n  File \"C:\\Users\\AD54619\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\thread.py\", line 59, in run\n    result = self.fn(*self.args, **self.kwargs)\n\n\n  File \"C:\\Users\\AD54619\\Text2Sql\\virtualen\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3712, in _invoke_step\n    return context.run(\n           ~~~~~~~~~~~^\n        step.invoke,\n        ^^^^^^^^^^^^\n        input,\n        ^^^^^^\n        child_config,\n        ^^^^^^^^^^^^^\n    )\n    ^\n\n\n  File \"C:\\Users\\AD54619\\Text2Sql\\virtualen\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 4719, in invoke\n    return self._call_with_config(\n           ~~~~~~~~~~~~~~~~~~~~~~^\n        self._invoke,\n        ^^^^^^^^^^^^^\n    ...<2 lines>...\n        **kwargs,\n        ^^^^^^^^^\n    )\n    ^\n\n\n  File \"C:\\Users\\AD54619\\Text2Sql\\virtualen\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 1925, in _call_with_config\n    context.run(\n    ~~~~~~~~~~~^\n        call_func_with_variable_args,  # type: ignore[arg-type]\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<4 lines>...\n        **kwargs,\n        ^^^^^^^^^\n    ),\n    ^\n\n\n  File \"C:\\Users\\AD54619\\Text2Sql\\virtualen\\Lib\\site-packages\\lang
































Type 'exit' or 'quit' to stop.

User Question: give me employee name whose salary is more than 50000
[DEBUG] Using tables: ['departments', 'employees']
Traceback (most recent call last):
  File "C:\Users\AD54619\Text2Sql\better_tiny.py", line 132, in <module>
    main()
    ~~~~^^
  File "C:\Users\AD54619\Text2Sql\better_tiny.py", line 108, in main
    chain = create_sql_query_chain(
        llm=llm,
    ...<2 lines>...
        top_k=3
    )
TypeError: create_sql_query_chain() got an unexpected keyword argument 'top_k'






























----
PS C:\Users\AD54619\Text2Sql> python better_tiny.py
⏳ Loading TinyLlama model (HuggingFace style)...
✅ Model loaded!
Device set to use cpu

🔹TinyLlama Chat w/ MySQL (Only raw DB data printed)

Type 'exit' or 'quit' to stop.

User Question: which employee had more than 5000 salary 
[DEBUG] Using tables: ['departments', 'employees']
Traceback (most recent call last):
  File "C:\Users\AD54619\Text2Sql\better_tiny.py", line 132, in <module>
    main()
    ~~~~^^
  File "C:\Users\AD54619\Text2Sql\better_tiny.py", line 104, in main
    chain = create_sql_query_chain(
        llm=llm,
    ...<2 lines>...
        # no 'output_parser' argument here, since your version doesn't support it
    )
  File "C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\langchain\chains\sql_database\query.py", line 122, in create_sql_query_chain  
    raise ValueError(
    ...<3 lines>...
    )
ValueError: Prompt must have input variables: 'input', 'top_k', 'table_info'. Received prompt with input variables: ['question']. Full prompt:

input_variables=['question'] input_types={} partial_variables={} template='Generate a valid MySQL query for the user question:\n{question}\n\nOnly output the SQL query. Nothing else.'

















🔹TinyLlama Chat w/ MySQL (Only raw DB data printed)

Type 'exit' or 'quit' to stop.

C:\Users\AD54619\Text2Sql\better_tiny.py:79: LangChainDeprecationWarning: The class `QuerySQLDataBaseTool` was deprecated in LangChain 0.3.12 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-community package and should be used instead. To use it run `pip install -U :class:`~langchain-community` and import as `from :class:`~langchain_community.tools import QuerySQLDatabaseTool``.
  query_tool = QuerySQLDataBaseTool(db=wide_db)
User Question: which employee has more than 50000 salary
[DEBUG] Using tables: ['departments', 'employees']
Traceback (most recent call last):
  File "C:\Users\AD54619\Text2Sql\better_tiny.py", line 129, in <module>
    main()
    ~~~~^^
  File "C:\Users\AD54619\Text2Sql\better_tiny.py", line 99, in main
    chain = create_sql_query_chain(
        llm=llm,
    ...<2 lines>...
        output_parser=StrOutputParser(),  # ensures raw string
    )
TypeError: create_sql_query_chain() got an unexpected keyword argument 'output_parser'





    
    sql_query = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]
    return sql_query

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Generate SQL from natural language')
    parser.add_argument('--question', type=str, help='The natural language question')
    parser.add_argument('--schema_file', type=str, help='File containing the database schema')
    
    args = parser.parse_args()
    
    if args.question and args.schema_file:
        with open(args.schema_file, 'r') as f:
            schema = f.read()
        
        sql = generate_sql(args.question, schema)
        print("\nGenerated SQL Query:")
        print(sql)
    else:
        # Use the example from your code if no arguments provided
        question = "What is the average, minimum, and maximum age for all French musicians?"
        schema = """
           "stadium" "Stadium_ID" int , "Location" text , "Name" text , "Capacity" int , "Highest" int , "Lowest" int , "Average" int , foreign_key:  primary key: "Stadium_ID" [SEP] "singer" "Singer_ID" int , "Name" text , "Country" text , "Song_Name" text , "Song_release_year" text , "Age" int , "Is_male" bool , foreign_key:  primary key: "Singer_ID" [SEP] "concert" "concert_ID" int , "concert_Name" text , "Theme" text , "Year" text , foreign_key: "Stadium_ID" text from "stadium" "Stadium_ID" , primary key: "concert_ID" [SEP] "singer_in_concert"  foreign_key: "concert_ID" int from "concert" "concert_ID" , "Singer_ID" text from "singer" "Singer_ID" , primary key: "concert_ID" "Singer_ID"
        """
        
        sql = generate_sql(question, schema)
        print("\nGenerated SQL Query:")
        print(sql)


PS C:\Users\AD54619\Text2Sql> python load.py --question "What is the average, minimum, and maximum age for all French musicians?" --schema_file schema.txt
Processing query...
C:\Users\AD54619\Text2Sql\virtualen\Lib\site-packages\transformers\generation\configuration_utils.py:676: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.
  warnings.warn(

Generated SQL Query:
SELECT avg(age), min(age), max(age) FROM singer WHERE country = 'France'
